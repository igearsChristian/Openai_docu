<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OpenAI Models Overview</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f4f4f4;
        }
        h1, h2, h3 {
            color: #333;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        table, th, td {
            border: 1px solid #ccc;
        }
        th, td {
            padding: 10px;
            text-align: left;
        }
        th {
            background-color: #eaeaea;
        }
        a {
            color: #007BFF;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        img {
            max-width: 100%;
            height: auto;
        }
    </style>
</head>
<body>

<h1>Models</h1>

<h2>Flagship models</h2>
<ul>
    <li><a href="/docs/models#gpt-4o">GPT-4o</a>: Our versatile, high-intelligence flagship model<br>
        Text and image input, text output<br>
        128k context length<br>
        Smarter model, higher price per token
    </li>
    <li><a href="/docs/models#gpt-4o-mini">GPT-4o mini</a>: Our fast, affordable small model for focused tasks<br>
        Text and image input, text output<br>
        128k context length<br>
        Faster model, lower price per token
    </li>
    <li><a href="/docs/models#o1">o1 & o1-mini</a>: Reasoning models that excel at complex, multi-step tasks<br>
        Text and image input, text output<br>
        128k context length<br>
        Uses additional tokens for reasoning
    </li>
    <li><a href="https://openai.com/api/pricing">Model pricing details</a></li>
</ul>

<h2>Models overview</h2>
<p>The OpenAI API is powered by a diverse set of models with different capabilities and price points. You can also make customizations to our models for your specific use case with <a href="/docs/guides/fine-tuning">fine-tuning</a>.</p>

<table>
    <tr>
        <th>Model</th>
        <th>Description</th>
    </tr>
    <tr>
        <td>GPT-4o</td>
        <td>Our versatile, high-intelligence flagship model</td>
    </tr>
    <tr>
        <td>GPT-4o-mini</td>
        <td>Our fast, affordable small model for focused tasks</td>
    </tr>
    <tr>
        <td>o1 and o1-mini</td>
        <td>Reasoning models that excel at complex, multi-step tasks</td>
    </tr>
    <tr>
        <td>GPT-4o Realtime</td>
        <td>GPT-4o models capable of realtime text and audio inputs and outputs</td>
    </tr>
    <tr>
        <td>GPT-4o Audio</td>
        <td>GPT-4o models capable of audio inputs and outputs via REST API</td>
    </tr>
    <tr>
        <td>GPT-4 Turbo and GPT-4</td>
        <td>The previous set of high-intelligence models</td>
    </tr>
    <tr>
        <td>GPT-3.5 Turbo</td>
        <td>A fast model for simple tasks, superceded by GPT-4o-mini</td>
    </tr>
    <tr>
        <td>DALLÂ·E</td>
        <td>A model that can generate and edit images given a natural language prompt</td>
    </tr>
    <tr>
        <td>TTS</td>
        <td>A set of models that can convert text into natural sounding spoken audio</td>
    </tr>
    <tr>
        <td>Whisper</td>
        <td>A model that can convert audio into text</td>
    </tr>
    <tr>
        <td>Embeddings</td>
        <td>A set of models that can convert text into a numerical form</td>
    </tr>
    <tr>
        <td>Moderation</td>
        <td>A fine-tuned model that can detect whether text may be sensitive or unsafe</td>
    </tr>
    <tr>
        <td>Deprecated</td>
        <td>A full list of models that have been deprecated along with the suggested replacement</td>
    </tr>
</table>

<h2>Context window</h2>
<p>Models on this page will list a <strong>context window</strong>, which refers to the maximum number of tokens that can be used in a single request, inclusive of both input, output, and reasoning tokens.</p>
<img src="https://cdn.openai.com/API/docs/images/context-window.png" alt="Context window visualization">

<h2>Model ID aliases and snapshots</h2>
<p>In the tables below, you will see <strong>model IDs</strong> that can be used in REST APIs to generate outputs. Some of these model IDs are <strong>aliases</strong> which point to specific <strong>dated snapshots</strong>.</p>

<h3>API request using a model alias</h3>
<pre><code>import OpenAI from "openai";
const openai = new OpenAI();

const completion = await openai.chat.completions.create({
    model: "gpt-4o",
    messages: [
        { role: "developer", content: "You are a helpful assistant." },
        { role: "user", content: "Write a haiku about recursion in programming." },
    ],
});

console.log(completion.choices[0].message);</code></pre>

<h2>How we use your data</h2>
<p>Your data is your data.</p>
<p>As of March 1, 2023, data sent to the OpenAI API will not be used to train or improve OpenAI models unless you explicitly opt-in to share data with us.</p>

<h2>Model endpoint compatibility</h2>
<table>
    <tr>
        <th>Endpoint</th>
        <th>Latest models</th>
    </tr>
    <tr>
        <td>/v1/assistants</td>
        <td>All GPT-4o, GPT-4o-mini, GPT-4, and GPT-3.5 Turbo models.</td>
    </tr>
    <tr>
        <td>/v1/audio/transcriptions</td>
        <td>whisper-1</td>
    </tr>
    <tr>
        <td>/v1/chat/completions</td>
        <td>All GPT-4o, GPT-4o-mini, GPT-4, and GPT-3.5 Turbo models.</td>
    </tr>
</table>

</body>
</html>