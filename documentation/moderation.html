<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Moderation API Documentation</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 20px;
            padding: 0;
            background-color: #f9f9f9;
        }
        h1, h2 {
            color: #333;
        }
        pre {
            background-color: #f4f4f4;
            padding: 10px;
            border-radius: 4px;
            overflow-x: auto;
        }
        code {
            background-color: #e8e8e8;
            padding: 2px 4px;
            border-radius: 4px;
        }
        a {
            color: #007bff;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>

<h1>Moderation</h1>
<p>Identify potentially harmful content in text and images.</p>

<p>The <a href="/docs/api-reference/moderations">moderations</a> endpoint is a tool you can use to check whether text or images are potentially harmful. Once harmful content is identified, developers can take corrective action like filtering content or intervening with user accounts creating offending content. The moderation endpoint is free to use.</p>

<h2>Models</h2>
<p>The models available for this endpoint are:</p>
<ul>
    <li><code>omni-moderation-latest</code>: This model and all snapshots support more categorization options and multi-modal inputs.</li>
    <li><code>text-moderation-latest</code> <strong>(Legacy)</strong>: Older model that supports only text inputs and fewer input categorizations. The newer omni-moderation models will be the best choice for new applications.</li>
</ul>

<h2>Quickstart</h2>
<p>The <a href="/docs/api-reference/moderations">moderation endpoint</a> can be used to classify both text and images. Below, you can find a few examples using our <a href="/docs/libraries">official SDKs</a>. These examples use the <code>omni-moderation-latest</code> <a href="/docs/models#moderation">model</a>:</p>

<h3>Moderate Text Inputs</h3>
<p>Get classification information for a text input:</p>

<pre><code>from openai import OpenAI
client = OpenAI()

response = client.moderations.create(
  model="omni-moderation-latest",
  input="...text to classify goes here...",
)

print(response)</code></pre>

<pre><code>import OpenAI from "openai";
const openai = new OpenAI();

const moderation = await openai.moderations.create({
  model: "omni-moderation-latest",
  input: "...text to classify goes here...",
});

console.log(moderation);</code></pre>

<pre><code>curl https://api.openai.com/v1/moderations \
-X POST \
-H "Content-Type: application/json" \
-H "Authorization: Bearer $OPENAI_API_KEY" \
-d '{
  "model": "omni-moderation-latest",
  "input": "...text to classify goes here..."
}'</code></pre>

<h3>Moderate Images and Text</h3>
<p>Get classification information for image and text input:</p>

<pre><code>from openai import OpenAI
client = OpenAI();

response = client.moderations.create(
  model="omni-moderation-latest",
  input=[
      {"type": "text", "text": "...text to classify goes here..."},
      {
          "type": "image_url",
          "image_url": {
              "url": "https://example.com/image.png",
              // can also use base64 encoded image URLs
              // "url": "data:image/jpeg;base64,abcdefg..."
          }
      },
  ],
)

print(response)</code></pre>

<pre><code>import OpenAI from "openai";
const openai = new OpenAI();

const moderation = await openai.moderations.create({
  model: "omni-moderation-latest",
  input: [
      { type: "text", text: "...text to classify goes here..." },
      {
          type: "image_url",
          image_url: {
              url: "https://example.com/image.png"
              // can also use base64 encoded image URLs
              // url: "data:image/jpeg;base64,abcdefg..."
          }
      }
  ],
});

console.log(moderation);</code></pre>

<pre><code>curl https://api.openai.com/v1/moderations \
-X POST \
-H "Content-Type: application/json" \
-H "Authorization: Bearer $OPENAI_API_KEY" \
-d '{
  "model": "omni-moderation-latest",
  "input": [
    { "type": "text", "text": "...text to classify goes here..." },
    {
      "type": "image_url",
      "image_url": {
        "url": "https://example.com/image.png"
      }
    }
  ]
}'</code></pre>

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Moderation API Example</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 20px;
            padding: 0;
            background-color: #f9f9f9;
        }
        h1, h2, h3 {
            color: #333;
        }
        pre {
            background-color: #f4f4f4;
            padding: 10px;
            border-radius: 4px;
            overflow-x: auto;
        }
        code {
            background-color: #e8e8e8;
            padding: 2px 4px;
            border-radius: 4px;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 8px;
            text-align: left;
        }
        th {
            background-color: #f2f2f2;
        }
        a {
            color: #007bff;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>

<h1>Moderation API Example Output</h1>
<p>Here is the full example output for an image input from a single frame of a war movie. The model correctly predicts indicators of violence in the image, with a <code>violence</code> category score of greater than 0.8.</p>

<pre><code>{
  "id": "modr-970d409ef3bef3b70c73d8232df86e7d",
  "model": "omni-moderation-latest",
  "results": [
    {
      "flagged": true,
      "categories": {
        "sexual": false,
        "sexual/minors": false,
        "harassment": false,
        "harassment/threatening": false,
        "hate": false,
        "hate/threatening": false,
        "illicit": false,
        "illicit/violent": false,
        "self-harm": false,
        "self-harm/intent": false,
        "self-harm/instructions": false,
        "violence": true,
        "violence/graphic": false
      },
      "category_scores": {
        "sexual": 2.34135824776394e-7,
        "sexual/minors": 1.6346470245419304e-7,
        "harassment": 0.0011643905680426018,
        "harassment/threatening": 0.0022121340080906377,
        "hate": 3.1999824407395835e-7,
        "hate/threatening": 2.4923252458203563e-7,
        "illicit": 0.0005227032493135171,
        "illicit/violent": 3.682979260160596e-7,
        "self-harm": 0.0011175734280627694,
        "self-harm/intent": 0.0006264858507989037,
        "self-harm/instructions": 7.368592981140821e-8,
        "violence": 0.8599265510337075,
        "violence/graphic": 0.37701736389561064
      },
      "category_applied_input_types": {
        "sexual": [
          "image"
        ],
        "sexual/minors": [],
        "harassment": [],
        "harassment/threatening": [],
        "hate": [],
        "hate/threatening": [],
        "illicit": [],
        "illicit/violent": [],
        "self-harm": [
          "image"
        ],
        "self-harm/intent": [
          "image"
        ],
        "self-harm/instructions": [
          "image"
        ],
        "violence": [
          "image"
        ],
        "violence/graphic": [
          "image"
        ]
      }
    }
  ]
}</code></pre>

<h2>Output Explanation</h2>
<p>The output from the models is described below. The JSON response contains information about what (if any) categories of content are present in the inputs, and to what degree the model believes them to be present.</p>

<table>
    <tr>
        <th>Field</th>
        <th>Description</th>
    </tr>
    <tr>
        <td><code>flagged</code></td>
        <td>Set to true if the model classifies the content as potentially harmful, false otherwise.</td>
    </tr>
    <tr>
        <td><code>categories</code></td>
        <td>Contains a dictionary of per-category violation flags. For each category, the value is true if the model flags the corresponding category as violated, false otherwise.</td>
    </tr>
    <tr>
        <td><code>category_scores</code></td>
        <td>Contains a dictionary of per-category scores output by the model, denoting the model's confidence that the input violates OpenAI's policy for the category. The value is between 0 and 1, where higher values denote higher confidence.</td>
    </tr>
    <tr>
        <td><code>category_applied_input_types</code></td>
        <td>This property contains information on which input types were flagged in the response, for each category. For example, if both the image and text inputs to the model are flagged for "violence/graphic", the violence/graphic property will be set to ["image", "text"]. This is only available on omni models.</td>
    </tr>
</table>

<h2>Content Classifications</h2>
<p>The table below describes the types of content that can be detected in the moderation API, along with what models and input types are supported for each category.</p>

<table>
    <tr>
        <th>Category</th>
        <th>Description</th>
        <th>Models</th>
        <th>Input Types</th>
    </tr>
    <tr>
        <td><code>harassment</code></td>
        <td>Content that expresses, incites, or promotes harassing language towards any target.</td>
        <td>All</td>
        <td>Text only</td>
    </tr>
    <tr>
        <td><code>harassment/threatening</code></td>
        <td>Harassment content that also includes violence or serious harm towards any target.</td>
        <td>All</td>
        <td>Text only</td>
    </tr>
    <tr>
        <td><code>hate</code></td>
        <td>Content that expresses, incites, or promotes hate based on race, gender, ethnicity, religion, nationality, sexual orientation, disability status, or caste. Hateful content aimed at non-protected groups (e.g. chess players) is harassment.</td>
        <td>All</td>
        <td>Text only</td>
    </tr>
    <tr>
        <td><code>hate/threatening</code></td>
        <td>Hateful content that also includes violence or serious harm towards the targeted group based on race, gender, ethnicity, religion, nationality, sexual orientation, disability status, or caste.</td>
        <td>All</td>
        <td>Text only</td>
    </tr>
    <tr>
        <td><code>illicit</code></td>
        <td>Content that gives advice or instruction on how to commit illicit acts. A phrase like "how to shoplift" would fit this category.</td>
        <td>Omni only</td>
        <td>Text only</td>
    </tr>
    <tr>
        <td><code>illicit/violent</code></td>
        <td>The same types of content flagged by the illicit category, but also includes references to violence or procuring a weapon.</td>
        <td>Omni only</td>
        <td>Text only</td>
    </tr>
    <tr>
        <td><code>self-harm</code></td>
        <td>Content that promotes, encourages, or depicts acts of self-harm, such as suicide, cutting, and eating disorders.</td>
        <td>All</td>
        <td>Text and image</td>
    </tr>
    <tr>
        <td><code>self-harm/intent</code></td>
        <td>Content where the speaker expresses that they are engaging or intend to engage in acts of self-harm, such as suicide, cutting, and eating disorders.</td>
        <td>All</td>
        <td>Text and image</td>
    </tr>
    <tr>
        <td><code>self-harm/instructions</code></td>
        <td>Content that encourages performing acts of self-harm, such as suicide, cutting, and eating disorders, or that gives instructions or advice on how to commit such acts.</td>
        <td>All</td>
        <td>Text and image</td>
    </tr>
    <tr>
        <td><code>sexual</code></td>
        <td>Content meant to arouse sexual excitement, such as the description of sexual activity, or that promotes sexual services (excluding sex education and wellness).</td>
        <td>All</td>
        <td>Text and image</td>
    </tr>
    <tr>
        <td><code>sexual/minors</code></td>
        <td>Sexual content that includes an individual who is under 18 years old.</td>
        <td>All</td>
        <td>Text only</td>
    </tr>
    <tr>
        <td><code>violence</code></td>
        <td>Content that depicts death, violence, or physical injury.</td>
        <td>All</td>
        <td>Text and images</td>
    </tr>
    <tr>
        <td><code>violence/graphic</code></td>
        <td>Content that depicts death, violence, or physical injury in graphic detail.</td>
        <td>All</td>
        <td>Text and images</td>
    </tr>
</table>
<br>
<span style="font-family: Arial, sans-serif; margin-bottom: 10px;">Was this page useful?</span>
<button class="button">👍</button>
<button class="button">👎</button>

</body>
</html>